# Learning to Isolate Muons in Data

Authors:
Edmund Witkowski,
Benjamin Nachman,
Daniel Whiteson

This repository contains the code for the paper ["Learning to Isolate Muons in Data"](https://arxiv.org/abs/2306.15737). In this code, several neural networks are trained and evaluated using Pytorch Lightning, as described in more depth in the paper. As provided, the scripts contain the hyperparameters used to obtain the results shown in the paper.

The dataset corresponding to this code may be found [on Zenodo](https://zenodo.org/record/8211425), and was compiled from the puclicly available [DoubleMuParked CMS dataset](https://opendata.cern.ch/record/6030).

## Organization

* Data is to be stored in the `src/data` directory. This should be obtained from the Zenodo link provided above and extracted + placed here as described in the section below.

* Figures are stored in the `src/figures` directory. These are provided in the repo, but may be generated using the `src/Figures.ipynb` notebook after running the scripts as described in the section below.

* The `src/cross_validation` directory contains scripts used to choose parameters (layer size, learning rate, and training length - the chosen parameters are provided in the scripts here, so running things as is should reproduce the results found in the paper) and prepare to run the scripts in `src/bootstrapping`. In addition to evaluating over a set of folds, the `src/cross_validation/iso_pT` scripts perform a scan over different numbers of isolation cones. `src/cross_validation/efp_search` contains code to perform a guided search to identify useful EFP observables from the large set generated by the `src/make_efps.py` script. Since there are far fewer EFPs in the set restricted to be quadratic, we use the code in `src/cross_validation/iso_efp_quadratic` to evaluate this set. The code in `src/cross_validation/sim_pfn` trains a PFN on simulated data in order to generate some demonstrative figures in `src/Figures.ipynb`. 

* The `src/bootstrapping` directory contains scripts used to evaluate each model over 100 ensembles using the parameters and EFPs found with the cross validation scripts. Once again the parameters used in the paper are provided in the scripts already, so if run as is they should reproduce the results in the paper.

* The `src/utilities` directory contains necessary functionality for the scripts in the other directories.

## Full Instructions

The following are ordered instructions to run the full set of scripts provided here.

* As written, scripts assume the presence of 4 GPUs. If this is not the case for your machine, each training script contains a `num_gpus` parameter which can be customized to your environment.

1. Download the `data.tar.gz` file from the link above.

2. Extract the contents of the file in the `src/data directory` with `tar -tzf my_tarball.tar.gz`.

3. Run the `src/make_efps.py` script to generate EFP observables. These will be generated using the data extracted above and placed in `src/data/cms_efp_k{kappa}_b{beta}` directories according to the kappa and beta lists specified in the script (by default these are set to what was used in the paper.) Note that each directory will be significantly larger than the original data files, as a large number of EFPs are generated for each parameterization.

4. Run the `cross_validation.py` scripts in each of the `src/cross_validation` subdirectories except for `src/cross_validation/efp_search`, `src/cross_validation/iso_pT`, and `src/cross_validation/sim_pfn`, for which `network_trainer.py`, `iso_scan.py`, and `train_script.py` should be run respectively.

5. Run the `model_summary.py` and `get_avg_epochs.py` scripts in all of the above directories except for `src/cross_validation/efp_search` `src/cross_validation/sim_pfn`.

6. Run the `bootstrapper.py` scripts in each of the `src/bootstrapping` subdirectories.

7. Run the `src/Figures.ipynb` notebook to generate the figures.